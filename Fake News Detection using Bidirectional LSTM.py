# -*- coding: utf-8 -*-
"""fake_news_detection_code_final_version.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n1-W5WKeUIcY5-zLxVd5V-sPY3s6qNtW

# TruthFinder: A Machine Learning Approach to Fake News Detection

This is the final version of the code portion of CS 680-001's final project. The purpose of this notebook is to classify fake news from real news using a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN).

**Team Members of Group 1**:
1. Masheha Rashid (masheha.rashid@my.liu.edu)
2. Humza Bhutta (Humza.Bhutta@my.liu.edu)
3. Maria Elizathe (maria.elizathe@my.liu.edu)
4. Harshkumar S. Ladva (harshkumarsavajibhai.ladva@my.liu.edu)

**Source Code**:
1. "Fake News Detection Using RNN" by Xingyu Bing (__[Kaggle Link](https://www.kaggle.com/code/therealcyberlord/fake-news-detection-using-rnn/notebook)__)
2. "Fake News Classifier | Bi-directional LSTM" by Iqman Singh Bhatia (__[Kaggle Link](https://www.kaggle.com/code/iqmansingh/fake-news-classifier-bi-directional-lstm/notebook)__)

**Dataset Used**:
* "FakeNewsNet" by Aleksei Golovin (__[Kaggle Link](https://www.kaggle.com/datasets/algord/fake-news/data)__)

## STEP 1: Importing Necessary Libraries & Packages
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import re
from tensorflow.keras.preprocessing.text import Tokenizer
import tensorflow as tf
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score
import seaborn as sns
plt.style.use('ggplot')

"""## STEP 2: Loading and Preprocessing the Data

### Reading the CSV file and Converting to a DataFrame
"""

news_df = pd.read_csv('/content/FakeNewsNet.csv')

print('Total number of news articles:', len(news_df))
news_df

"""### Cleaning and Reformatting the DataFrame

* 0 = real news artilces
* 1 = fake news article
"""

#renaming the "real" column to "label"
news_df.rename(columns = {'real': 'label'}, inplace = True)

#dropna() is used to remove missing values
news_df.dropna(inplace=True)

news_df.reset_index(inplace=True)

#The irrelevant columns are dropped from the dataset
news_df.drop(['index','news_url','source_domain','tweet_num'],axis=1,inplace=True)

print('Total number of news articles after cleaning:', len(news_df))
news_df

"""### The distribution of Fake News and Real News"""

grouped = news_df.groupby(news_df.label)
real_df = grouped.get_group(0)
fake_df = grouped.get_group(1)

plt.figure(figsize=(10, 5))
plt.bar('Fake News', len(fake_df), color='orange')
plt.bar('Real News', len(real_df), color='green')
plt.title('Distribution of Fake News and Real News', size=15)
plt.xlabel('News Type', size=15)
plt.ylabel('# of News Articles', size=15)

total_len = len(fake_df) + len(real_df)
plt.figure(figsize=(10, 5))
plt.bar('Fake News', len(fake_df) / total_len, color='orange')
plt.bar('Real News', len(real_df) / total_len, color='green')
plt.title('Distribution of Fake News and Real News', size=15)
plt.xlabel('News Type', size=15)
plt.ylabel('Proportion of News Articles', size=15)

print('Number of fake news articles:', len(fake_df))
print('Number of real news articles:', len(real_df))
print('Difference of news articles:', abs(len(real_df) - len(fake_df)))

"""## STEP 3: Splitting Training/Testing Data & Tokenization"""

features = news_df['title']
targets = news_df['label']

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.20, random_state=18)

"""### Normalizing our data: lower case, get rid of extra spaces, and url links."""

def normalize(data):
    normalized = []
    for i in data:
        i = i.lower()
        # get rid of non words and extra spaces
        i = re.sub('\\W', ' ', i)
        i = re.sub('\n', '', i)
        i = re.sub(' +', ' ', i)
        i = re.sub('^ ', '', i)
        i = re.sub(' $', '', i)
        normalized.append(i)
    return normalized

X_train = normalize(X_train)
X_test = normalize(X_test)

"""### Convert text to vectors, our classifier only takes numerical data."""

max_vocab = 10000
tokenizer = Tokenizer(num_words=max_vocab)
tokenizer.fit_on_texts(X_train)

# tokenize the text into vectors
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

"""### Apply padding so we have the same length for each article"""

X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=256)
X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=256)

"""## STEP 4: Building the Recurrent Neural Network (RNN) Model"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(max_vocab, 128),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,  return_sequences=True)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid'),
])

model.summary()

"""## STEP 5: Training the Model

### Using early stop to stop training when the validation loss no longer improve
"""

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)

model.compile(optimizer="adam",
              loss="binary_crossentropy",
              metrics=["accuracy"])

history = model.fit(X_train, y_train,
                    epochs=20,
                    validation_data=(X_test, y_test),
                    batch_size=64,
                    shuffle=True,
                    callbacks=[early_stop])

"""## STEP 6: Evaluating the Results

### Visualize the training progress over time
"""

history_dict = history.history

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']
epochs = history.epoch

plt.figure(figsize=(12,9))
plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss', size=20)
plt.xlabel('Epochs', size=20)
plt.ylabel('Loss', size=20)
plt.legend(prop={'size': 20})
plt.show()

plt.figure(figsize=(12,9))
plt.plot(epochs, acc, 'g', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy', size=20)
plt.xlabel('Epochs', size=20)
plt.ylabel('Accuracy', size=20)
plt.legend(prop={'size': 20})
plt.ylim((0.5,1))
plt.show()

"""### Evaluating the testing set"""

model.evaluate(X_test, y_test)

pred = model.predict(X_test)

binary_predictions = []

for i in pred:
    if i <= 0.5:
        binary_predictions.append(0) #predicts the article shows real news
    else:
        binary_predictions.append(1) #predicts the articles shows fake news

print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))
print('Precision on testing set:', precision_score(binary_predictions, y_test))
print('Recall on testing set:', recall_score(binary_predictions, y_test))

"""### Confusion Matrix"""

matrix = confusion_matrix(binary_predictions, y_test, normalize='all')
plt.figure(figsize=(16, 10))
ax= plt.subplot()
sns.heatmap(matrix, annot=True, ax = ax)

# labels, title and ticks
ax.set_xlabel('Predicted Labels', size=20)
ax.set_ylabel('True Labels', size=20)
ax.set_title('Confusion Matrix', size=20)
ax.xaxis.set_ticklabels([0,1], size=15)
ax.yaxis.set_ticklabels([0,1], size=15)

